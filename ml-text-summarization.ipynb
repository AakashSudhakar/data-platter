{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to Text Summarization in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 0: Imports and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aakashsudhakar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aakashsudhakar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK modules\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Beautiful Soup and URL querying utilities\n",
    "import bs4 as BeautifulSoup\n",
    "from urllib import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialize our data processing engine for miscellaneous text data online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert processor engine initialization here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Overview of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Major Types of Text Summarization:\n",
    "    - Extraction-based summarization\n",
    "    - Abstraction-based summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to Perform Text Summarization:\n",
    "    1. Convert the paragraph into sentences.\n",
    "    2. Perform text processing.\n",
    "    3. Perform tokenization.\n",
    "    4. Evaluated the weighted occurrence frequency of the words. \n",
    "    5. Substitute words with their weighted frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "![](https://paper-attachments.dropbox.com/s_5DD7360138DEDEB8828AD11E4B5921DC0A55833560A1BC79C451FADB6E7D209D_1554467410003_image.png)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Breakdown of Code Constructs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"https://en.wikipedia.org/wiki/20th_century\"\n",
    "\n",
    "data_read = urlopen(PATH_DATA).read()\n",
    "data_parsed = BeautifulSoup.BeautifulSoup(data_read, \"html.parser\")\n",
    "\n",
    "data_paragraphs = data_parsed.find_all(\"p\")\n",
    "\n",
    "data_content = str()\n",
    "for paragraph in paragraphs:\n",
    "    data_content += paragraph.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_table(text):\n",
    "    \"\"\" Function to create frequency histogram of word occurrences across input text. \"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    raw_words_from_data = word_tokenize(text)\n",
    "    stem = PorterStemmer()\n",
    "    # Create frequency table via dictionary operations\n",
    "    frequency_table = dict()\n",
    "    for word in raw_words_from_data:\n",
    "        word_root = stem.stem(word)\n",
    "        if word_root in stop_words:\n",
    "            continue\n",
    "        if word_root in frequency_table:\n",
    "            frequency_table[word_root] += 1\n",
    "        else:\n",
    "            frequency_table[word_root] = 1\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Tokenize the article into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(data_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Find the weighted frequencies of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_scores(sentences, frequency_table, num_chars=7):\n",
    "    \"\"\" Function to create weighted frequency scores from parsed sentences using frequency table. \"\"\"\n",
    "    sentence_weight = dict()\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:num_chars] in sentence_weight:\n",
    "                    sentence_weight[sentence[:num_chars]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:num_chars]] = frequency_table[word_weight]\n",
    "        sentence_weight[sentence[:num_chars]] /= sentence_wordcount_without_stop_words\n",
    "    return sentence_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate the threshold of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_threshold(sentence_weight):\n",
    "    \"\"\" Function to get the average weighted score of a sentence. \"\"\"\n",
    "    sum_values = 0\n",
    "    for element in sentence_weight:\n",
    "        sum_values += sentence_weight[element]\n",
    "    return (sum_values / len(sentence_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Obtain the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_summary(sentences, sentence_weight, threshold, num_chars=7):\n",
    "    \"\"\" Function to create summary statement of article using weighted sentence data and relative threshold. \"\"\"\n",
    "    sentence_counter, article_summary = 0, str()\n",
    "    for sentence in sentences:\n",
    "        if sentence[:num_chars] in sentence_weight and sentence_weight[sentence[:num_chars]] >= (threshold):\n",
    "            article_summary += \" {}\".format(sentence)\n",
    "            sentence_counter += 1\n",
    "    return article_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap this all up into a nice outer function and run our summarization analysis on our sample Wikipedia and check our results!\n",
    "\n",
    "Since this is extraction-based, it won't be nearly as nicely grammatical and well-structured as an abstraction-based (deep learning and advanced modeling) approach, but it should be sufficient to give us an adequate summary of the article's topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_text_summary(text):\n",
    "    frequency_table = create_frequency_table(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_scores = calculate_sentence_scores(sentences, frequency_table)\n",
    "    threshold = calculate_average_threshold(sentence_scores)\n",
    "    text_summary = get_text_summary(sentences, sentence_scores, 1.5 * threshold)\n",
    "    return text_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Terms like ideology, world war, genocide, and nuclear war entered common usage. Humans explored space for the first time, taking their first footsteps on the Moon. However, these same wars resulted in the destruction of the imperial system. The victorious Bolsheviks then established the Soviet Union, the world's first communist state. At the beginning of the period, the British Empire was the world's most powerful nation,[12] having acted as the world's policeman for the past century. In total, World War II left some 60 million people dead. With the Axis defeated and Britain and France rebuilding, the United States and the Soviet Union were left standing as the world's only superpowers. At the beginning of the century, strong discrimination based on race and sex was significant in general society. During the century, the social taboo of sexism fell. Communications and information technology, transportation technology, and medical advances had radically altered daily lives. With the end of colonialism and the Cold War, nearly a billion people in Africa were left in new nation states after centuries of foreign domination. Since the US was in a dominant position, a major part of the process was Americanization. Terrorism, dictatorship, and the spread of nuclear weapons were pressing global issues. Millions were infected with HIV, the virus which causes AIDS. This includes deaths caused by wars, genocide, politicide and mass murders. Prior to the 20th century, music was generally only experienced in live performances. Later in the 20th century, the development of computers led to the establishment of a theory of computation.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_text_summary(data_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
